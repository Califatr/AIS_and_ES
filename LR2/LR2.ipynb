{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da1911c4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "\n",
    " Вариант №5\n",
    " 4 'comp.sys.ibm.pc.hardware'\n",
    " 14 'sci.med'\n",
    " 18 'talk.politics.mideast'\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abd10dc",
   "metadata": {},
   "source": [
    "2) Импортировать необходимые для работы библиотеки и модули "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dae64bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import nltk\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064a362b",
   "metadata": {},
   "source": [
    "3) Загрузить обучающую и экзаменационную выборку в соответствие с вариантом \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad721965",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categories = ['comp.sys.ibm.pc.hardware', 'sci.med', 'talk.politics.mideast']\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "\n",
    "twenty_train_full = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42, remove=remove)\n",
    "twenty_test_full = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42, remove=remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e848f88",
   "metadata": {},
   "source": [
    "4) Вывести на экран по одному-два документа каждого класса. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a5e8422",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AY>  In many recent advertisements I have seen both \"486DX-50\" and \"486DX\n",
      "AY>based systems. Does the first really exists and does it imply that all\n",
      "AY>circuitry on the motherboard with it works at that speed, as opposite \n",
      "AY>latter, where only the internals of the CPU are working at 50MHz?\n",
      "AY>\n",
      "AY> Many thanx in advance!\n",
      "AY>\n",
      "AY>Andrew.\n",
      "\n",
      "Andrew, yes there is a DX and DX2 version of the 50MHz 486.  If you are \n",
      "considering buying one or the other, definitely go for the DX with a nice \n",
      "size external cache!  The performance is far greater.\n",
      "\n",
      "The DX2 only has the internal 8k cache to work with at 50MHz, while the DX \n",
      "has a potentially much larger cache to work at 50MHz with.  Neither \n",
      "systems could actually run a program out of main memory, since DRAM is \n",
      "still too slow for that high of bus speed ( 60ns = 16.66MHz < 50MHz ).\n",
      "\n",
      "-rdd\n",
      "\n",
      "---\n",
      " . WinQwk 2.0b#0 . Unregistered Evaluation Copy\n",
      " * KMail 2.95d W-NET HQ, hal9k.ann-arbor.mi.us, +1 313 663 4173 or 3959\n",
      "                                                               \n",
      "\n",
      "\n",
      "Let's face it, if the words don't get into your noggin in the first place, \n",
      "there's no hope. Now tell us, 'SDPA.ORG', a mouthpiece of the fascist x-Soviet \n",
      "Armenian Government: what was your role in the murder of Orhan Gunduz and \n",
      "Kemal Arikan? How many more Muslims will be slaughtered by 'SDPA.ORG' as \n",
      "publicly declared and filed with the legal authorities? \n",
      "\n",
      "\n",
      " \"...that more people have to die...\" \n",
      "\n",
      "                    SDPA <91@urartu.UUCP>\n",
      "\n",
      "  \"Yes, I stated this and stand by it.\"\n",
      "\n",
      "                    SDPA <255@urartu.UUCP>\n",
      "\n",
      "\n",
      "    \tJanuary 28, 1982 - Los Angeles\n",
      "\tKemal Arikan is slaughtered by two Armenians while driving to work. \n",
      "\n",
      "    \tMarch 22, 1982 - Cambridge, Massachusetts\n",
      "\tPrelude to grisly murder. A gift and import shop belonging to\n",
      "\tOrhan Gunduz is blown up. Gunduz receives an ultimatum: Either \n",
      "        he gives up his honorary position or he will be \"executed\". He \n",
      "        refuses. \"Responsibility\" is claimed by JCAG and SDPA.\n",
      "\n",
      "    \tMay 4, 1982 - Cambridge, Massachusetts\n",
      "\tOrhan Gunduz, the Turkish honorary consul in Boston, would not bow \n",
      "\tto the Armenian terrorist ultimatum that he give up his title of \n",
      "\t\"honorary consul\". Now he is attacked and murdered in cold blood.\n",
      "\tPresident Reagan orders an all-out manhunt-to no avail. An eye-\n",
      "\twitness who gave a description of the murderer is shot down.  He \n",
      "\tsurvives... but falls silent. One of the most revolting \"triumphs\" in \n",
      "\tthe senseless, mindless history of Armenian terrorism. Such a murder \n",
      "\tbrings absolutely nothing - except an ego boost for the murderer \n",
      "\twithin the Armenian terrorist underworld, which is already wallowing \n",
      "\tin self-satisfaction.\n",
      " \n",
      "Were you involved in the murder of Sarik Ariyak? \n",
      "\n",
      "   \tDecember 17, 1980 - Sydney\n",
      "\tTwo Nazi Armenians massacre Sarik Ariyak and his bodyguard, Engin \n",
      "        Sever. JCAG and SDPA claim responsibility.\n",
      "\n",
      "\n",
      "Source: Edward K. Boghosian, \"Radical Group Hosts Well-Attended Solidarity\n",
      "Meeting,\" The Armenian Reporter, May 1, 1986, pp. 1 & 18.\n",
      "\n",
      "ATHENS, Greece - An array of representatives of Greek political parties,\n",
      "including the ruling PASOK party, and a host of political groups, both\n",
      "Armenian and non-Armenian, joined to voice their solidarity with the \n",
      "Armenian people in their pursuit of their cause and activities of a new\n",
      "Armenian political force were voiced here on Sunday, April 20 during\n",
      "the 2nd International Meeting of Solidarity with the Armenian People. And\n",
      "judging from encouraging messages offered by the representatives of these\n",
      "political groups and organizations, at least here in Greece, the Armenian\n",
      "Cause enjoys abundant support from a wide spectrum of the political world.\n",
      "\n",
      "The International Meeting of Solidarity was sponsored by the Greek branch of\n",
      "the Armenian Popular Movement, a comparatively new political force headed\n",
      "by younger generations of Armenians, who openly profess their support of the\n",
      "armed struggle and of the Armenian Secret Army for the Liberation of Armenia\n",
      "(ASALA). The organization has branches in various European and Middle Eastern\n",
      "countries and the United States although some of these branches appear to\n",
      "have gone through a switch of loyalties because of the split within the ranks\n",
      "of ASALA...\n",
      "\n",
      "Voicing the support of PASOK, the ruling party in Greece, to the Armenian\n",
      "people, was Mr. Charalambidi Michalis, a member of the Central Committee of\n",
      "the party and the Greek member of the Permanent People's Tribunal...\n",
      "Explaining the goals and aspirations of the Armenian Popular Movement \n",
      "was Ara Sarkisian. Significant was the address delivered by Mr. Bassam \n",
      "Abu-Salim, on behalf of the Popular Front for the movement's continued \n",
      "support of the Armenians' armed struggle in their pursuit of their cause, \n",
      "pledging that Palestinian operated and run training camps would always be \n",
      "open to Armenian youth who need training for such a struggle. Later, Mr. \n",
      "Abu-Salim, answering a question put to him by this writer, affirmed that \n",
      "his organization had always trained Armenian members of ASALA and that\n",
      "this policy will continue. \"The doors of our camps are always open to \n",
      "Armenian freedom fighters,\" he affirmed.\n",
      "\n",
      "Among the prominent Greek politicians who attended the conference was the son\n",
      "of Prime Minister Papandreou, who himself holds a post in the Greek cabinet;\n",
      "two members of the Cypriot Parliament who had journeyed to Athens for the\n",
      "specific purpose of attending the international gathering; representatives of\n",
      "the Christian Democratic party, EDIK Center party, two wings of the Communist\n",
      "party, representatives of an assortment of labor unions and trade associations,\n",
      "a number of mayors of Greek towns and cities; two Greek members of the\n",
      "European Parliament and other members of the Greek Parliament were also among\n",
      "those who participated in the international conference. Also on hand to follow\n",
      "the deliberations was the ambassador of Bulgaria in Athens.\n",
      "\n",
      "More than significant was the large number of messages received by the \n",
      "organizers, including the following: Palestinian National Revolutionary\n",
      "Movement, Fatah; Popular Front for the Liberation of Palestine-General\n",
      "Command; the Central Committee of the Palestinian National Liberation\n",
      "Movement-Fatah; the Socialist Progressive Party of Lebanon; Arab Socialist\n",
      "Labor Party; the Kurdistan Democratic Union of Iraq; and numerous other\n",
      "international groups, all noted for their radical stand in the Israeli-\n",
      "Palestinian conflict.\n",
      "\n",
      "                 SUPPORT FROM ARF-RM\n",
      "\n",
      "Among messages received from Armenian groups was the Armenian Revolutionary\n",
      "Federation-Revolutionary Movement, the group that has claimed the abduction\n",
      "and assassination of key party leaders in Lebanon accused of selling out to\n",
      "foreign interests and powers. The message clearly gave its support to the\n",
      "Armenian Popular Movement pledging that the Revolutionary movement will\n",
      "continue to \"reveal the realities, no matter how bitter or tragic they are,\"\n",
      "to expose the anti-Armenian activities of the leaders of the Dashnag \"Bureau.\"\n",
      "The message was taken as an indication of the link, loose as it may be, that\n",
      "exists between the dissident Dashnag group and the Armenian Popular Movement,\n",
      "open supporters of ASALA and armed struggle.\n",
      "\n",
      "The Armenian Popular Movement has set up its headquarters in a suburb of the\n",
      "Greek capital, known as Neos Kosmos, where there is a large Armenian presence.\n",
      "The headquarters are located in a two-story building, which appears to have\n",
      "turned into a beehive of activity on the part of scores of Armenian youth, who\n",
      "prefer to give their first names only when invited to introduce themselves...\n",
      "\n",
      "Now any comment?\n",
      "\n",
      "#From: vd8@cunixb.cc.columbia.edu (Vedat  Dogan)\n",
      "#Subject: Re:Addressing.....\n",
      "#Message-ID: <1993Apr8.233029.29094@news.columbia.edu>\n",
      "\n",
      " \n",
      " \n",
      "n>crap posted by Mr. [(*]!\n",
      " \n",
      " o boy!   \n",
      " \n",
      " Please, can you tell us why those quotes are \"crap\"?..because you do not \n",
      " like them!!!...because they really exist...why?\n",
      " \n",
      " As I said in my previous posting, those quotes exactly exist in the source \n",
      " given by Serdar Argic .. \n",
      "  \n",
      " You couldn't reject it...\n",
      " \n",
      " \n",
      " Here we go again..\n",
      " In the book I have, both the front page and the Author's preface give \n",
      " the same year: 1923 and 15 January, 1923, respectively!\n",
      " (Anyone can check it at her/his library,if not, I can send you the copies of\n",
      " pages, please ask by sct) \n",
      " \n",
      " \n",
      "I really don't care what year it was first published(1923 or 1924)\n",
      "What I care about is what the book writes about murders, tortures,et..in\n",
      "the given quotes by Serdar Argic, and your denial of these quotes..and your\n",
      "groundless accussations, etc. \n",
      " \n",
      "[...]\n",
      " \n",
      " \n",
      " I claim I have a book in my hand published in 1923(first publication)\n",
      " and it exactly has the same quoted info as the book published\n",
      " in 1934(Serdar Argic's Reference) has..You couldn't reject it..but, now you\n",
      " are avoiding the real issues by twisting around..\n",
      " \n",
      " Let's see how you lie!..(from 'non-existing' quotes to re-publication)\n",
      " \n",
      " First you said there was no such a quote in the given reference..You\n",
      " called Serdar Argic a liar!..\n",
      " I said to you, NO, MR.Davidian, there exactly existed such a quote...\n",
      " (I even gave the call number, page numbers..you could't reject it.)\n",
      " \n",
      " And now, you are lying again and talking about \"modified,re-published book\"\n",
      "(without any proof :how, when, where, by whom, etc..)..\n",
      " (by the way, how is it possible to re-publish the book in 1923 if it was\n",
      "  first published in 1924(your claim).I am sure that you have some 'pretty \n",
      "  well suited theories', as usual)\n",
      " \n",
      " And I am ready to send the copies of the necessary pages to anybody who\n",
      " wants to compare the fact and Mr.Davidian's lies...I also give the call number\n",
      " and page numbers again for the library use, which are:  \n",
      "                 949.6 R 198\n",
      "   \n",
      "  and the page numbers to verify the quotes:218 and 215\n",
      "              \n",
      "     \n",
      " \n",
      " \n",
      " Now, are you claiming that there can't be such a reference by saying \"it is\n",
      " not possible...\" ..If not, what is your point?\n",
      " \n",
      " Differences in the number of pages?\n",
      " Mine was published in 1923..Serdar Argic's was in 1934..\n",
      " No need to use the same book size and the same letter \n",
      " charachter in both publications,etc, etc.. does it give you an idea!!\n",
      " \n",
      " The issue was not the number of pages the book has..or the year\n",
      " first published.. \n",
      " And you tried to hide the whole point..\n",
      " the point is that both books have the exactly the same quotes about\n",
      " how moslems are killed, tortured,etc by Armenians..and those quotes given \n",
      " by Serdar Argic exist!! \n",
      " It was the issue, wasn't-it?  \n",
      " \n",
      " you were not able to object it...Does it bother you anyway? \n",
      " \n",
      " You name all these tortures and murders (by Armenians) as a \"crap\"..\n",
      " People who think like you are among the main reasons why the World still\n",
      " has so many \"craps\" in the 1993. \n",
      " \n",
      " Any question?\n",
      " \n",
      "Serdar Argic\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train_full.data[0])\n",
    "print(twenty_train_full.data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "919a3dfb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why? There is no need to go into this.......\n",
      "\n",
      "\n",
      "especially this rivetting piece of information.\n",
      "\n",
      "\n",
      "As I remember, someone did ask if UV had a speach code. But, really,\n",
      "there is no need for this brief survey course. \n",
      "\n",
      "\n",
      "How wonderful for you.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I have no idea what this guy means but the Syrian Jews are not allowed\n",
      "to leave Syria because Assad welshed on his promise and is not letting\n",
      "them go. Israel has nothing to do with it.\n",
      "\n",
      "As for the other Arab countries there are still small communities left\n",
      "in some Arab countries. Morocco has the largest group I think comprising\n",
      "perhaps just over a thousand (but I have lost the exact figure. Maybe\n",
      "someone will be so kind as to post it). There are communities left in\n",
      "Yemen (which went to the polls yesterday in what might appear to be a\n",
      "free-ish election), Algeria (this is a tiny group, a couple of leftist\n",
      "intellectuals I think), of course Syria and Lebannon.\n",
      "\n",
      "The circumstances of the departure of the Jews from various Arab countries\n",
      "is controversial in some cases - like Iraq - and I do not want to get into\n",
      "a dispute about it. Egypt expelled most of its community outright. Most of\n",
      "the French North African Jews left rather than face Independence. I think\n",
      "that Moroccans might have been encouraged by some AntiSemitic acts but I\n",
      "am not sure. Someone else around here will know for sure. There are claims\n",
      "that Israeli intellegence officers spread rumours around Algeria that the\n",
      "Jews would not be welcome but this is probably just propaganda. It would\n",
      "take a very stupid person not to realise the benefits of a move to France\n",
      "(as most did) or to Israel. Yemeni Jews were airlifted to Israel. Those\n",
      "left were rumoured to have another airlift last year but I heard nothing\n",
      "about it so I guess it was just a rumour. Any I left out except Iraq?\n",
      "\n",
      "Joseph Askew\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(twenty_test_full.data[0])\n",
    "print(twenty_test_full.data[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13565f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "5) Применить стемминг, записав обработанные выборки (тестовую и обучающую) в новые переменные. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94c050af",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/nicolay/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import *\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a06e896",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def stemming(data):\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    stem = []\n",
    "    for text in data:\n",
    "        nltk_tokens = word_tokenize(text)\n",
    "        line = ''.join([' ' + porter_stemmer.stem(word) for word in nltk_tokens])\n",
    "        stem.append(line)\n",
    "    return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "556503b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stem_train = stemming(twenty_train_full.data)\n",
    "stem_test = stemming(twenty_test_full.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4abda5e0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ay > in mani recent advertis i have seen both `` 486dx-50 '' and `` 486dx ay > base system . doe the first realli exist and doe it impli that all ay > circuitri on the motherboard with it work at that speed , as opposit ay > latter , where onli the intern of the cpu are work at 50mhz ? ay > ay > mani thanx in advanc ! ay > ay > andrew . andrew , ye there is a dx and dx2 version of the 50mhz 486 . if you are consid buy one or the other , definit go for the dx with a nice size extern cach ! the perform is far greater . the dx2 onli ha the intern 8k cach to work with at 50mhz , while the dx ha a potenti much larger cach to work at 50mhz with . neither system could actual run a program out of main memori , sinc dram is still too slow for that high of bu speed ( 60n = 16.66mhz < 50mhz ) . -rdd -- - . winqwk 2.0b # 0 . unregist evalu copi * kmail 2.95d w-net hq , hal9k.ann-arbor.mi.u , +1 313 663 4173 or 3959\n"
     ]
    }
   ],
   "source": [
    "print(stem_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb2da467",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " whi ? there is no need to go into thi ....... especi thi rivet piec of inform . as i rememb , someon did ask if uv had a speach code . but , realli , there is no need for thi brief survey cours . how wonder for you .\n"
     ]
    }
   ],
   "source": [
    "print(stem_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb1780f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "6) Провести векторизацию выборки: \n",
    "a. Векторизовать обучающую и тестовую выборки простым подсчетом слов (CountVectorizer) и значеним max_features = 10000 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38f4dda6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15834539",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Векторизация обучающей и тестовой выборки простым подсчетом слов (CountVectorizer) и значением max_features = 10.000\n",
    "vect_without_stop = CountVectorizer(max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12a749fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = vect_without_stop.fit_transform(twenty_train_full.data)\n",
    "test_data = vect_without_stop.transform(twenty_test_full.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80092e0a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sort_by_tf(input_str):\n",
    "    return input_str[1]\n",
    "\n",
    "def top_terms(vector, data, count):\n",
    "    x = list(zip(vector.get_feature_names_out(), np.ravel(data.sum(axis=0))))\n",
    "    x.sort(key=sort_by_tf, reverse=True)\n",
    "    return x[:count]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f59431",
   "metadata": {},
   "source": [
    "b. Вывести и проанализировать первые 20 наиболее частотных слов всей выборки и каждого класса по-отдельности. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e29f2e0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'the': 14650},\n",
       " {'of': 7249},\n",
       " {'to': 6579},\n",
       " {'and': 6307},\n",
       " {'in': 4663},\n",
       " {'that': 3192},\n",
       " {'is': 3189},\n",
       " {'it': 2491},\n",
       " {'for': 2343},\n",
       " {'on': 1807},\n",
       " {'you': 1799},\n",
       " {'with': 1691},\n",
       " {'this': 1654},\n",
       " {'have': 1545},\n",
       " {'as': 1533},\n",
       " {'was': 1485},\n",
       " {'not': 1481},\n",
       " {'are': 1478},\n",
       " {'be': 1343},\n",
       " {'by': 1340}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_terms_without_stop = [{term[0]: term[1]} for term in top_terms(vect_without_stop, train_data, 20)]\n",
    "top_terms_without_stop\n",
    "\n",
    "top_terms_without_stop_test = [{term[0]: term[1]} for term in top_terms(vect_without_stop, test_data, 20)]\n",
    "top_terms_without_stop_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f9aea4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "c. Применить процедуру отсечения стоп-слов и повторить пункт b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0926dea4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vect_stop = CountVectorizer(max_features=10000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0666451a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data_stop = vect_stop.fit_transform(twenty_train_full.data)\n",
    "test_data_stop = vect_stop.transform(twenty_test_full.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ced268c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'people': 558},\n",
       " {'like': 439},\n",
       " {'just': 407},\n",
       " {'know': 399},\n",
       " {'armenian': 392},\n",
       " {'don': 374},\n",
       " {'said': 366},\n",
       " {'time': 317},\n",
       " {'armenians': 314},\n",
       " {'new': 309},\n",
       " {'does': 307},\n",
       " {'israel': 304},\n",
       " {'use': 294},\n",
       " {'ve': 271},\n",
       " {'think': 258},\n",
       " {'jews': 256},\n",
       " {'did': 247},\n",
       " {'jewish': 246},\n",
       " {'good': 227},\n",
       " {'92': 217}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_terms_stop = [{term[0]: term[1]} for term in top_terms(vect_stop, train_data_stop, 20)]\n",
    "top_terms_stop\n",
    "\n",
    "top_terms_stop_test = [{term[0]: term[1]} for term in top_terms(vect_stop, test_data_stop, 20)]\n",
    "top_terms_stop_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c49cece",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "d. Провести пункты a – c для обучающей и тестовой выборки, для которой проведена процедура стемминга. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "087d281b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vect_stem_without_stop = CountVectorizer(max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb1dd35a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data_without_stop_stem = vect_stem_without_stop.fit_transform(stem_train)\n",
    "test_data_without_stop_stem = vect_stem_without_stop.transform(stem_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74a0fb12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'the': 14650},\n",
       " {'of': 7249},\n",
       " {'to': 6580},\n",
       " {'and': 6307},\n",
       " {'in': 4664},\n",
       " {'is': 3244},\n",
       " {'that': 3201},\n",
       " {'it': 2798},\n",
       " {'for': 2343},\n",
       " {'on': 1809},\n",
       " {'you': 1798},\n",
       " {'with': 1691},\n",
       " {'have': 1668},\n",
       " {'thi': 1654},\n",
       " {'be': 1532},\n",
       " {'not': 1532},\n",
       " {'as': 1531},\n",
       " {'are': 1511},\n",
       " {'wa': 1508},\n",
       " {'by': 1338}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_terms_stem = [{term[0]: term[1]} for term in top_terms(vect_stem_without_stop, train_data_without_stop_stem, 20)]\n",
    "top_terms_stem\n",
    "\n",
    "top_terms_stem_test = [{term[0]: term[1]} for term in top_terms(vect_stem_without_stop, test_data_without_stop_stem, 20)]\n",
    "top_terms_stem_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf9f9af",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "d. Провести пункты a – c для обучающей и тестовой выборки, для которой проведена процедура стемминга. Применена процедура отсечения стоп слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08395cd5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vect_stem = CountVectorizer(max_features=10000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fbcc9bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data_stop_stem = vect_stem.fit_transform(stem_train)\n",
    "test_data_stop_stem = vect_stem.transform(stem_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b29490fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'thi': 1654},\n",
       " {'wa': 1508},\n",
       " {'ha': 748},\n",
       " {'armenian': 706},\n",
       " {'use': 687},\n",
       " {'peopl': 577},\n",
       " {'ani': 551},\n",
       " {'like': 476},\n",
       " {'know': 452},\n",
       " {'hi': 418},\n",
       " {'time': 408},\n",
       " {'just': 407},\n",
       " {'doe': 390},\n",
       " {'muslim': 376},\n",
       " {'onli': 371},\n",
       " {'did': 369},\n",
       " {'said': 366},\n",
       " {'year': 360},\n",
       " {'work': 342},\n",
       " {'new': 330}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_terms_stop_stem = [{term[0]: term[1]} for term in top_terms(vect_stem, train_data_stop_stem, 20)]\n",
    "top_terms_stop_stem\n",
    "\n",
    "top_terms_stop_stem_test = [{term[0]: term[1]} for term in top_terms(vect_stem, test_data_stop_stem, 20)]\n",
    "top_terms_stop_stem_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae93e0d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Векторизовать выборки с помощью TfidfTransformer (с использованием TF и TF-IDF взвешиваний) и повторить пункты b-d. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b04d3df",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " Без использования стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41946fb9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37672b7c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tf = TfidfTransformer(use_idf=False)\n",
    "tfidf = TfidfTransformer(use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba29e15c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data_tf = tf.fit_transform(train_data)\n",
    "test_data_tf = tf.transform(test_data)\n",
    "\n",
    "train_data_tfidf = tfidf.fit_transform(train_data)\n",
    "test_data_tfidf = tfidf.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58cedc43",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'the': 159.2169690232235},\n",
       " {'to': 89.02190713477806},\n",
       " {'of': 83.45129921232822},\n",
       " {'and': 73.7766936838158},\n",
       " {'in': 60.65224299548882},\n",
       " {'is': 58.103868781563605},\n",
       " {'that': 53.177739920859196},\n",
       " {'it': 48.24061768176479},\n",
       " {'you': 45.649903936602},\n",
       " {'for': 42.72281944930034},\n",
       " {'this': 37.901483549050184},\n",
       " {'have': 35.800297109784495},\n",
       " {'on': 33.416342525930226},\n",
       " {'are': 32.4915980194941},\n",
       " {'not': 32.124698387113376},\n",
       " {'with': 31.14359170735619},\n",
       " {'as': 30.193569888878972},\n",
       " {'be': 29.125311312829243},\n",
       " {'or': 27.659896044595506},\n",
       " {'was': 26.0177820514447}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_terms_tf = [{term[0]: term[1]} for term in top_terms(vect_without_stop, train_data_tf, 20)]\n",
    "top_terms_tf\n",
    "\n",
    "top_terms_tf_test = [{term[0]: term[1]} for term in top_terms(vect_without_stop, test_data_tf, 20)]\n",
    "top_terms_tf_test\n",
    "\n",
    "top_terms_tfidf = [{term[0]: term[1]} for term in top_terms(vect_without_stop, train_data_tfidf, 20)]\n",
    "top_terms_tfidf\n",
    "\n",
    "top_terms_tfidf_test = [{term[0]: term[1]} for term in top_terms(vect_without_stop, test_data_tfidf, 20)]\n",
    "top_terms_tfidf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6cdc26",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "С использованием стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e08cd3d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tf = TfidfTransformer(use_idf=False)\n",
    "tfidf = TfidfTransformer(use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cee32073",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data_stop_tf = tf.fit_transform(train_data_stop)\n",
    "test_data_stop_tf = tf.transform(test_data_stop)\n",
    "\n",
    "train_data_stop_tfidf = tfidf.fit_transform(train_data_stop)\n",
    "test_data_stop_tfidf = tfidf.transform(test_data_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bab80cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'know': 19.78579921737784},\n",
       " {'like': 17.72640179203392},\n",
       " {'people': 17.7089654853161},\n",
       " {'just': 17.631226432525903},\n",
       " {'don': 17.583760771958584},\n",
       " {'does': 17.22809995409527},\n",
       " {'drive': 16.39874301043245},\n",
       " {'thanks': 15.453835857073658},\n",
       " {'ve': 14.080995472361815},\n",
       " {'use': 14.06988552250666},\n",
       " {'think': 13.975194482131897},\n",
       " {'israel': 13.496273726006486},\n",
       " {'good': 12.577620578291661},\n",
       " {'card': 12.276145758372772},\n",
       " {'did': 11.839884300272598},\n",
       " {'need': 11.59412077354018},\n",
       " {'jews': 11.412098006263552},\n",
       " {'problem': 11.396809292843278},\n",
       " {'muslims': 11.244332076286735},\n",
       " {'information': 10.72185387994127}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_terms_stop_tf = [{term[0]: term[1]} for term in top_terms(vect_stop, train_data_stop_tf, 20)]\n",
    "top_terms_stop_tf\n",
    "\n",
    "top_terms_stop_tf_test = [{term[0]: term[1]} for term in top_terms(vect_stop, test_data_stop_tf, 20)]\n",
    "top_terms_stop_tf_test\n",
    "\n",
    "top_terms_stop_tfidf = [{term[0]: term[1]} for term in top_terms(vect_stop, train_data_stop_tfidf, 20)]\n",
    "top_terms_stop_tfidf\n",
    "\n",
    "top_terms_stop_tfidf_test = [{term[0]: term[1]} for term in top_terms(vect_stop, test_data_stop_tfidf, 20)]\n",
    "top_terms_stop_tfidf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a412af",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Со стеммингом без стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7093aff3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tf = TfidfTransformer(use_idf=False)\n",
    "tfidf = TfidfTransformer(use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a46a4bdb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data_stem_tf = tf.fit_transform(train_data_without_stop_stem)\n",
    "test_data_stem_tf = tf.transform(test_data_without_stop_stem)\n",
    "\n",
    "train_data_stem_tfidf = tfidf.fit_transform(train_data_without_stop_stem)\n",
    "test_data_stem_tfidf = tfidf.transform(test_data_without_stop_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b278031",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'the': 157.2388941502928},\n",
       " {'to': 88.25882757708708},\n",
       " {'of': 82.15071361679951},\n",
       " {'and': 72.81946837666995},\n",
       " {'in': 59.67514134362165},\n",
       " {'is': 58.74700675437686},\n",
       " {'that': 53.114529463275495},\n",
       " {'it': 50.782768659461645},\n",
       " {'you': 45.24027565870208},\n",
       " {'for': 42.32351737189909},\n",
       " {'have': 37.89706132683007},\n",
       " {'thi': 37.640352013093114},\n",
       " {'on': 32.969598013545124},\n",
       " {'are': 32.733953715289694},\n",
       " {'not': 32.53959169338456},\n",
       " {'do': 32.37287087935601},\n",
       " {'be': 31.33777132043142},\n",
       " {'with': 30.746733916646296},\n",
       " {'as': 29.68626987221284},\n",
       " {'or': 27.490714607187865}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_terms_stem_tf = [{term[0]: term[1]} for term in top_terms(vect_stem_without_stop, train_data_stem_tf, 20)]\n",
    "top_terms_stem_tf\n",
    "\n",
    "top_terms_stem_tf_test = [{term[0]: term[1]} for term in top_terms(vect_stem_without_stop, test_data_stem_tf, 20)]\n",
    "top_terms_stem_tf_test\n",
    "\n",
    "top_terms_stem_tfidf = [{term[0]: term[1]} for term in top_terms(vect_stem_without_stop, train_data_stem_tfidf, 20)]\n",
    "top_terms_stem_tfidf\n",
    "\n",
    "top_terms_stem_tfidf_test = [{term[0]: term[1]} for term in top_terms(vect_stem_without_stop, test_data_stem_tfidf, 20)]\n",
    "top_terms_stem_tfidf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54e100",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Со стеммингом с использованием стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2f2d72b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tf = TfidfTransformer(use_idf=False)\n",
    "tfidf = TfidfTransformer(use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c39743f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data_stem_stop_tf = tf.fit_transform(train_data_stop_stem)\n",
    "test_data_stem_stop_tf = tf.transform(test_data_stop_stem)\n",
    "\n",
    "train_data_stem_stop_tfidf = tfidf.fit_transform(train_data_stop_stem)\n",
    "test_data_stem_stop_tfidf = tfidf.transform(test_data_stop_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29563dfb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'kuvvetli': 38.58159096500337},\n",
       " {'liu': 36.12468490625079},\n",
       " {'keysystem': 35.07900385428372},\n",
       " {'papa': 33.899805109818885},\n",
       " {'drain': 33.22247165159427},\n",
       " {'download': 31.356326600450455},\n",
       " {'tire': 24.756486685752243},\n",
       " {'va': 23.68612643837865},\n",
       " {'tile': 23.60052634582734},\n",
       " {'dunya': 21.770502304466586},\n",
       " {'vertic': 21.18233857137946},\n",
       " {'hada': 19.81800160459357},\n",
       " {'tour': 19.631632693113296},\n",
       " {'joke': 19.001475698647734},\n",
       " {'dip': 18.620097671734133},\n",
       " {'powel': 18.270319216644406},\n",
       " {'nan': 17.341536187667092},\n",
       " {'broccoli': 16.80690032882596},\n",
       " {'honeywell': 16.734896985500633},\n",
       " {'weyrich': 16.175907790854883}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_terms_stem_stop_tf = [{term[0]: term[1]} for term in top_terms(vect_stem, train_data_stop_tf, 20)]\n",
    "top_terms_stem_stop_tf\n",
    "\n",
    "top_terms_stem_stop_tf_test = [{term[0]: term[1]} for term in top_terms(vect_stem, test_data_stop_tf, 20)]\n",
    "top_terms_stem_stop_tf_test\n",
    "\n",
    "top_terms_stem_stop_tfidf = [{term[0]: term[1]} for term in top_terms(vect_stem, train_data_stop_tf, 20)]\n",
    "top_terms_stem_stop_tfidf\n",
    "\n",
    "top_terms_stem_stop_tfidf_test = [{term[0]: term[1]} for term in top_terms(vect_stem, test_data_stop_tf, 20)]\n",
    "top_terms_stem_stop_tfidf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ec7a5d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "По результатам пункта 6 заполнить таблицы наиболее частотными терминами обучающей выборки и каждого класса по отдельности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17759eee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7349d6cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "columns = pd.MultiIndex.from_product([['Count', 'TF', 'TF-IDF'], ['Без стоп-слов', 'С стоп-словами']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8792cd68",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Без стемминга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "914e3db3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Count</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TF</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TF-IDF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Без стоп-слов</th>\n",
       "      <th>С стоп-словами</th>\n",
       "      <th>Без стоп-слов</th>\n",
       "      <th>С стоп-словами</th>\n",
       "      <th>Без стоп-слов</th>\n",
       "      <th>С стоп-словами</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'the': 20927}</td>\n",
       "      <td>{'people': 1049}</td>\n",
       "      <td>{'the': 593.3256841596507}</td>\n",
       "      <td>{'know': 54.741560260006736}</td>\n",
       "      <td>{'the': 227.9558306920963}</td>\n",
       "      <td>{'know': 27.728806445196387}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'of': 10253}</td>\n",
       "      <td>{'know': 727}</td>\n",
       "      <td>{'to': 324.35056386604447}</td>\n",
       "      <td>{'just': 52.77569413890487}</td>\n",
       "      <td>{'to': 128.8488479541235}</td>\n",
       "      <td>{'just': 26.560026322737713}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'to': 9895}</td>\n",
       "      <td>{'like': 705}</td>\n",
       "      <td>{'of': 284.32768892589365}</td>\n",
       "      <td>{'like': 52.615200558633546}</td>\n",
       "      <td>{'of': 122.79902042561119}</td>\n",
       "      <td>{'people': 25.89595434402102}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'and': 9303}</td>\n",
       "      <td>{'don': 690}</td>\n",
       "      <td>{'and': 246.055767993875}</td>\n",
       "      <td>{'people': 50.36062593469473}</td>\n",
       "      <td>{'and': 104.65751352906601}</td>\n",
       "      <td>{'like': 25.473994640289288}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'in': 6686}</td>\n",
       "      <td>{'just': 678}</td>\n",
       "      <td>{'is': 211.8971731527514}</td>\n",
       "      <td>{'don': 48.3356858391453}</td>\n",
       "      <td>{'is': 90.84365943836319}</td>\n",
       "      <td>{'don': 25.138891964059667}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'that': 5243}</td>\n",
       "      <td>{'said': 617}</td>\n",
       "      <td>{'it': 185.64787315807015}</td>\n",
       "      <td>{'does': 43.35324301900809}</td>\n",
       "      <td>{'in': 86.92944107213987}</td>\n",
       "      <td>{'israel': 24.77736759387494}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'is': 5012}</td>\n",
       "      <td>{'armenian': 611}</td>\n",
       "      <td>{'in': 185.35842967934371}</td>\n",
       "      <td>{'time': 37.27135075539442}</td>\n",
       "      <td>{'it': 84.30246063746429}</td>\n",
       "      <td>{'drive': 24.12998277979711}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'it': 4456}</td>\n",
       "      <td>{'edu': 587}</td>\n",
       "      <td>{'that': 168.34202229537448}</td>\n",
       "      <td>{'think': 36.292810556154315}</td>\n",
       "      <td>{'that': 79.44737741122822}</td>\n",
       "      <td>{'does': 23.83766430970143}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'you': 3309}</td>\n",
       "      <td>{'time': 571}</td>\n",
       "      <td>{'you': 131.24534400434962}</td>\n",
       "      <td>{'israel': 35.5649078550382}</td>\n",
       "      <td>{'you': 74.58316802538543}</td>\n",
       "      <td>{'edu': 20.714882299147984}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'for': 3249}</td>\n",
       "      <td>{'drive': 523}</td>\n",
       "      <td>{'for': 116.12627141885021}</td>\n",
       "      <td>{'drive': 32.30302778343974}</td>\n",
       "      <td>{'for': 58.15598723309614}</td>\n",
       "      <td>{'time': 20.349971601319805}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'on': 2649}</td>\n",
       "      <td>{'armenians': 511}</td>\n",
       "      <td>{'this': 94.73104189498784}</td>\n",
       "      <td>{'edu': 32.04577092336103}</td>\n",
       "      <td>{'this': 50.54309921413386}</td>\n",
       "      <td>{'think': 20.319287163702608}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'with': 2582}</td>\n",
       "      <td>{'use': 509}</td>\n",
       "      <td>{'have': 90.34966254353837}</td>\n",
       "      <td>{'use': 31.273268013974864}</td>\n",
       "      <td>{'not': 49.02490900988524}</td>\n",
       "      <td>{'scsi': 19.654863630271507}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'they': 2458}</td>\n",
       "      <td>{'israel': 502}</td>\n",
       "      <td>{'with': 88.53034271562834}</td>\n",
       "      <td>{'thanks': 29.87072552182338}</td>\n",
       "      <td>{'are': 48.95164833232471}</td>\n",
       "      <td>{'thanks': 19.2117559423666}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'this': 2421}</td>\n",
       "      <td>{'turkish': 474}</td>\n",
       "      <td>{'on': 87.38918274513544}</td>\n",
       "      <td>{'good': 26.74248581100969}</td>\n",
       "      <td>{'have': 48.24550427656501}</td>\n",
       "      <td>{'card': 19.165641352111816}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'are': 2413}</td>\n",
       "      <td>{'scsi': 466}</td>\n",
       "      <td>{'not': 86.91825929049}</td>\n",
       "      <td>{'card': 26.492309800567398}</td>\n",
       "      <td>{'on': 47.8903986738175}</td>\n",
       "      <td>{'use': 18.351130157961457}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'not': 2409}</td>\n",
       "      <td>{'think': 452}</td>\n",
       "      <td>{'are': 84.46973508912207}</td>\n",
       "      <td>{'problem': 26.022392993607035}</td>\n",
       "      <td>{'with': 47.12072738733223}</td>\n",
       "      <td>{'good': 16.541818286397422}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'was': 2407}</td>\n",
       "      <td>{'does': 449}</td>\n",
       "      <td>{'be': 79.94429654337597}</td>\n",
       "      <td>{'help': 25.264808465903076}</td>\n",
       "      <td>{'be': 45.22377483664475}</td>\n",
       "      <td>{'help': 16.153930034104715}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'have': 2243}</td>\n",
       "      <td>{'jews': 424}</td>\n",
       "      <td>{'as': 67.25737298825979}</td>\n",
       "      <td>{'did': 24.7113547918968}</td>\n",
       "      <td>{'as': 42.44215634594219}</td>\n",
       "      <td>{'problem': 16.099688236177283}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'be': 2098}</td>\n",
       "      <td>{'did': 401}</td>\n",
       "      <td>{'or': 66.304294374055}</td>\n",
       "      <td>{'new': 24.524137168129766}</td>\n",
       "      <td>{'my': 39.23353188963498}</td>\n",
       "      <td>{'israeli': 15.900155757721613}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'as': 2062}</td>\n",
       "      <td>{'new': 381}</td>\n",
       "      <td>{'if': 60.82774382644909}</td>\n",
       "      <td>{'way': 23.039159762462827}</td>\n",
       "      <td>{'or': 38.69725612115456}</td>\n",
       "      <td>{'did': 15.810382536473046}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Count                                                TF  \\\n",
       "     Без стоп-слов      С стоп-словами                 Без стоп-слов   \n",
       "0   {'the': 20927}    {'people': 1049}    {'the': 593.3256841596507}   \n",
       "1    {'of': 10253}       {'know': 727}    {'to': 324.35056386604447}   \n",
       "2     {'to': 9895}       {'like': 705}    {'of': 284.32768892589365}   \n",
       "3    {'and': 9303}        {'don': 690}     {'and': 246.055767993875}   \n",
       "4     {'in': 6686}       {'just': 678}     {'is': 211.8971731527514}   \n",
       "5   {'that': 5243}       {'said': 617}    {'it': 185.64787315807015}   \n",
       "6     {'is': 5012}   {'armenian': 611}    {'in': 185.35842967934371}   \n",
       "7     {'it': 4456}        {'edu': 587}  {'that': 168.34202229537448}   \n",
       "8    {'you': 3309}       {'time': 571}   {'you': 131.24534400434962}   \n",
       "9    {'for': 3249}      {'drive': 523}   {'for': 116.12627141885021}   \n",
       "10    {'on': 2649}  {'armenians': 511}   {'this': 94.73104189498784}   \n",
       "11  {'with': 2582}        {'use': 509}   {'have': 90.34966254353837}   \n",
       "12  {'they': 2458}     {'israel': 502}   {'with': 88.53034271562834}   \n",
       "13  {'this': 2421}    {'turkish': 474}     {'on': 87.38918274513544}   \n",
       "14   {'are': 2413}       {'scsi': 466}       {'not': 86.91825929049}   \n",
       "15   {'not': 2409}      {'think': 452}    {'are': 84.46973508912207}   \n",
       "16   {'was': 2407}       {'does': 449}     {'be': 79.94429654337597}   \n",
       "17  {'have': 2243}       {'jews': 424}     {'as': 67.25737298825979}   \n",
       "18    {'be': 2098}        {'did': 401}       {'or': 66.304294374055}   \n",
       "19    {'as': 2062}        {'new': 381}     {'if': 60.82774382644909}   \n",
       "\n",
       "                                                          TF-IDF  \\\n",
       "                     С стоп-словами                Без стоп-слов   \n",
       "0      {'know': 54.741560260006736}   {'the': 227.9558306920963}   \n",
       "1       {'just': 52.77569413890487}    {'to': 128.8488479541235}   \n",
       "2      {'like': 52.615200558633546}   {'of': 122.79902042561119}   \n",
       "3     {'people': 50.36062593469473}  {'and': 104.65751352906601}   \n",
       "4         {'don': 48.3356858391453}    {'is': 90.84365943836319}   \n",
       "5       {'does': 43.35324301900809}    {'in': 86.92944107213987}   \n",
       "6       {'time': 37.27135075539442}    {'it': 84.30246063746429}   \n",
       "7     {'think': 36.292810556154315}  {'that': 79.44737741122822}   \n",
       "8      {'israel': 35.5649078550382}   {'you': 74.58316802538543}   \n",
       "9      {'drive': 32.30302778343974}   {'for': 58.15598723309614}   \n",
       "10       {'edu': 32.04577092336103}  {'this': 50.54309921413386}   \n",
       "11      {'use': 31.273268013974864}   {'not': 49.02490900988524}   \n",
       "12    {'thanks': 29.87072552182338}   {'are': 48.95164833232471}   \n",
       "13      {'good': 26.74248581100969}  {'have': 48.24550427656501}   \n",
       "14     {'card': 26.492309800567398}     {'on': 47.8903986738175}   \n",
       "15  {'problem': 26.022392993607035}  {'with': 47.12072738733223}   \n",
       "16     {'help': 25.264808465903076}    {'be': 45.22377483664475}   \n",
       "17        {'did': 24.7113547918968}    {'as': 42.44215634594219}   \n",
       "18      {'new': 24.524137168129766}    {'my': 39.23353188963498}   \n",
       "19      {'way': 23.039159762462827}    {'or': 38.69725612115456}   \n",
       "\n",
       "                                     \n",
       "                     С стоп-словами  \n",
       "0      {'know': 27.728806445196387}  \n",
       "1      {'just': 26.560026322737713}  \n",
       "2     {'people': 25.89595434402102}  \n",
       "3      {'like': 25.473994640289288}  \n",
       "4       {'don': 25.138891964059667}  \n",
       "5     {'israel': 24.77736759387494}  \n",
       "6      {'drive': 24.12998277979711}  \n",
       "7       {'does': 23.83766430970143}  \n",
       "8       {'edu': 20.714882299147984}  \n",
       "9      {'time': 20.349971601319805}  \n",
       "10    {'think': 20.319287163702608}  \n",
       "11     {'scsi': 19.654863630271507}  \n",
       "12     {'thanks': 19.2117559423666}  \n",
       "13     {'card': 19.165641352111816}  \n",
       "14      {'use': 18.351130157961457}  \n",
       "15     {'good': 16.541818286397422}  \n",
       "16     {'help': 16.153930034104715}  \n",
       "17  {'problem': 16.099688236177283}  \n",
       "18  {'israeli': 15.900155757721613}  \n",
       "19      {'did': 15.810382536473046}  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(columns=columns)\n",
    "\n",
    "df1['Count', 'Без стоп-слов'] = top_terms_without_stop\n",
    "df1['TF', 'Без стоп-слов'] = top_terms_tf\n",
    "df1['TF-IDF', 'Без стоп-слов'] = top_terms_tfidf\n",
    "\n",
    "df1['Count', 'С стоп-словами'] = top_terms_stop\n",
    "df1['TF', 'С стоп-словами'] = top_terms_stop_tf\n",
    "df1['TF-IDF', 'С стоп-словами'] = top_terms_stop_tfidf\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93543ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(columns=columns)\n",
    "df2['Count', 'С стоп-словами'] = top_terms_stop\n",
    "df2['TF', 'С стоп-словами'] = top_terms_stop_tf\n",
    "df2['TF-IDF', 'С стоп-словами'] = top_terms_stop_tfidf\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80a5abd1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Count</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TF</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TF-IDF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Без стоп-слов</th>\n",
       "      <th>С стоп-словами</th>\n",
       "      <th>Без стоп-слов</th>\n",
       "      <th>С стоп-словами</th>\n",
       "      <th>Без стоп-слов</th>\n",
       "      <th>С стоп-словами</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'the': 14650}</td>\n",
       "      <td>{'people': 558}</td>\n",
       "      <td>{'the': 403.27852840515715}</td>\n",
       "      <td>{'know': 38.58159096500337}</td>\n",
       "      <td>{'the': 159.2169690232235}</td>\n",
       "      <td>{'know': 19.78579921737784}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'of': 7249}</td>\n",
       "      <td>{'like': 439}</td>\n",
       "      <td>{'to': 217.90584846740072}</td>\n",
       "      <td>{'like': 36.12468490625079}</td>\n",
       "      <td>{'to': 89.02190713477806}</td>\n",
       "      <td>{'like': 17.72640179203392}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'to': 6579}</td>\n",
       "      <td>{'just': 407}</td>\n",
       "      <td>{'of': 188.1102669338932}</td>\n",
       "      <td>{'just': 35.07900385428372}</td>\n",
       "      <td>{'of': 83.45129921232822}</td>\n",
       "      <td>{'people': 17.7089654853161}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'and': 6307}</td>\n",
       "      <td>{'know': 399}</td>\n",
       "      <td>{'and': 169.6239850732778}</td>\n",
       "      <td>{'people': 33.899805109818885}</td>\n",
       "      <td>{'and': 73.7766936838158}</td>\n",
       "      <td>{'just': 17.631226432525903}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'in': 4663}</td>\n",
       "      <td>{'armenian': 392}</td>\n",
       "      <td>{'is': 133.31865743350403}</td>\n",
       "      <td>{'don': 33.22247165159427}</td>\n",
       "      <td>{'in': 60.65224299548882}</td>\n",
       "      <td>{'don': 17.583760771958584}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'that': 3192}</td>\n",
       "      <td>{'don': 374}</td>\n",
       "      <td>{'in': 125.38323764466679}</td>\n",
       "      <td>{'does': 31.356326600450455}</td>\n",
       "      <td>{'is': 58.103868781563605}</td>\n",
       "      <td>{'does': 17.22809995409527}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'is': 3189}</td>\n",
       "      <td>{'said': 366}</td>\n",
       "      <td>{'that': 109.29535702682418}</td>\n",
       "      <td>{'think': 24.756486685752243}</td>\n",
       "      <td>{'that': 53.177739920859196}</td>\n",
       "      <td>{'drive': 16.39874301043245}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'it': 2491}</td>\n",
       "      <td>{'time': 317}</td>\n",
       "      <td>{'it': 104.13977257385334}</td>\n",
       "      <td>{'use': 23.68612643837865}</td>\n",
       "      <td>{'it': 48.24061768176479}</td>\n",
       "      <td>{'thanks': 15.453835857073658}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'for': 2343}</td>\n",
       "      <td>{'armenians': 314}</td>\n",
       "      <td>{'for': 83.38528167692749}</td>\n",
       "      <td>{'thanks': 23.60052634582734}</td>\n",
       "      <td>{'you': 45.649903936602}</td>\n",
       "      <td>{'ve': 14.080995472361815}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'on': 1807}</td>\n",
       "      <td>{'new': 309}</td>\n",
       "      <td>{'you': 77.5189215357162}</td>\n",
       "      <td>{'drive': 21.770502304466586}</td>\n",
       "      <td>{'for': 42.72281944930034}</td>\n",
       "      <td>{'use': 14.06988552250666}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'you': 1799}</td>\n",
       "      <td>{'does': 307}</td>\n",
       "      <td>{'this': 69.59671509746121}</td>\n",
       "      <td>{'ve': 21.18233857137946}</td>\n",
       "      <td>{'this': 37.901483549050184}</td>\n",
       "      <td>{'think': 13.975194482131897}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'with': 1691}</td>\n",
       "      <td>{'israel': 304}</td>\n",
       "      <td>{'have': 64.8416836220305}</td>\n",
       "      <td>{'good': 19.81800160459357}</td>\n",
       "      <td>{'have': 35.800297109784495}</td>\n",
       "      <td>{'israel': 13.496273726006486}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'this': 1654}</td>\n",
       "      <td>{'use': 294}</td>\n",
       "      <td>{'on': 59.378895325157465}</td>\n",
       "      <td>{'time': 19.631632693113296}</td>\n",
       "      <td>{'on': 33.416342525930226}</td>\n",
       "      <td>{'good': 12.577620578291661}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'have': 1545}</td>\n",
       "      <td>{'ve': 271}</td>\n",
       "      <td>{'with': 56.453491676804056}</td>\n",
       "      <td>{'israel': 19.001475698647734}</td>\n",
       "      <td>{'are': 32.4915980194941}</td>\n",
       "      <td>{'card': 12.276145758372772}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'as': 1533}</td>\n",
       "      <td>{'think': 258}</td>\n",
       "      <td>{'not': 55.012670530019044}</td>\n",
       "      <td>{'did': 18.620097671734133}</td>\n",
       "      <td>{'not': 32.124698387113376}</td>\n",
       "      <td>{'did': 11.839884300272598}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'was': 1485}</td>\n",
       "      <td>{'jews': 256}</td>\n",
       "      <td>{'are': 54.230257103284806}</td>\n",
       "      <td>{'problem': 18.270319216644406}</td>\n",
       "      <td>{'with': 31.14359170735619}</td>\n",
       "      <td>{'need': 11.59412077354018}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'not': 1481}</td>\n",
       "      <td>{'did': 247}</td>\n",
       "      <td>{'be': 49.588587994454585}</td>\n",
       "      <td>{'need': 17.341536187667092}</td>\n",
       "      <td>{'as': 30.193569888878972}</td>\n",
       "      <td>{'jews': 11.412098006263552}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'are': 1478}</td>\n",
       "      <td>{'jewish': 246}</td>\n",
       "      <td>{'as': 46.076040061871375}</td>\n",
       "      <td>{'card': 16.80690032882596}</td>\n",
       "      <td>{'be': 29.125311312829243}</td>\n",
       "      <td>{'problem': 11.396809292843278}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'be': 1343}</td>\n",
       "      <td>{'good': 227}</td>\n",
       "      <td>{'or': 45.885330296526945}</td>\n",
       "      <td>{'help': 16.734896985500633}</td>\n",
       "      <td>{'or': 27.659896044595506}</td>\n",
       "      <td>{'muslims': 11.244332076286735}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'by': 1340}</td>\n",
       "      <td>{'92': 217}</td>\n",
       "      <td>{'but': 41.98162538060753}</td>\n",
       "      <td>{'way': 16.175907790854883}</td>\n",
       "      <td>{'was': 26.0177820514447}</td>\n",
       "      <td>{'information': 10.72185387994127}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Count                                                TF  \\\n",
       "     Без стоп-слов      С стоп-словами                 Без стоп-слов   \n",
       "0   {'the': 14650}     {'people': 558}   {'the': 403.27852840515715}   \n",
       "1     {'of': 7249}       {'like': 439}    {'to': 217.90584846740072}   \n",
       "2     {'to': 6579}       {'just': 407}     {'of': 188.1102669338932}   \n",
       "3    {'and': 6307}       {'know': 399}    {'and': 169.6239850732778}   \n",
       "4     {'in': 4663}   {'armenian': 392}    {'is': 133.31865743350403}   \n",
       "5   {'that': 3192}        {'don': 374}    {'in': 125.38323764466679}   \n",
       "6     {'is': 3189}       {'said': 366}  {'that': 109.29535702682418}   \n",
       "7     {'it': 2491}       {'time': 317}    {'it': 104.13977257385334}   \n",
       "8    {'for': 2343}  {'armenians': 314}    {'for': 83.38528167692749}   \n",
       "9     {'on': 1807}        {'new': 309}     {'you': 77.5189215357162}   \n",
       "10   {'you': 1799}       {'does': 307}   {'this': 69.59671509746121}   \n",
       "11  {'with': 1691}     {'israel': 304}    {'have': 64.8416836220305}   \n",
       "12  {'this': 1654}        {'use': 294}    {'on': 59.378895325157465}   \n",
       "13  {'have': 1545}         {'ve': 271}  {'with': 56.453491676804056}   \n",
       "14    {'as': 1533}      {'think': 258}   {'not': 55.012670530019044}   \n",
       "15   {'was': 1485}       {'jews': 256}   {'are': 54.230257103284806}   \n",
       "16   {'not': 1481}        {'did': 247}    {'be': 49.588587994454585}   \n",
       "17   {'are': 1478}     {'jewish': 246}    {'as': 46.076040061871375}   \n",
       "18    {'be': 1343}       {'good': 227}    {'or': 45.885330296526945}   \n",
       "19    {'by': 1340}         {'92': 217}    {'but': 41.98162538060753}   \n",
       "\n",
       "                                                           TF-IDF  \\\n",
       "                     С стоп-словами                 Без стоп-слов   \n",
       "0       {'know': 38.58159096500337}    {'the': 159.2169690232235}   \n",
       "1       {'like': 36.12468490625079}     {'to': 89.02190713477806}   \n",
       "2       {'just': 35.07900385428372}     {'of': 83.45129921232822}   \n",
       "3    {'people': 33.899805109818885}     {'and': 73.7766936838158}   \n",
       "4        {'don': 33.22247165159427}     {'in': 60.65224299548882}   \n",
       "5      {'does': 31.356326600450455}    {'is': 58.103868781563605}   \n",
       "6     {'think': 24.756486685752243}  {'that': 53.177739920859196}   \n",
       "7        {'use': 23.68612643837865}     {'it': 48.24061768176479}   \n",
       "8     {'thanks': 23.60052634582734}      {'you': 45.649903936602}   \n",
       "9     {'drive': 21.770502304466586}    {'for': 42.72281944930034}   \n",
       "10        {'ve': 21.18233857137946}  {'this': 37.901483549050184}   \n",
       "11      {'good': 19.81800160459357}  {'have': 35.800297109784495}   \n",
       "12     {'time': 19.631632693113296}    {'on': 33.416342525930226}   \n",
       "13   {'israel': 19.001475698647734}     {'are': 32.4915980194941}   \n",
       "14      {'did': 18.620097671734133}   {'not': 32.124698387113376}   \n",
       "15  {'problem': 18.270319216644406}   {'with': 31.14359170735619}   \n",
       "16     {'need': 17.341536187667092}    {'as': 30.193569888878972}   \n",
       "17      {'card': 16.80690032882596}    {'be': 29.125311312829243}   \n",
       "18     {'help': 16.734896985500633}    {'or': 27.659896044595506}   \n",
       "19      {'way': 16.175907790854883}     {'was': 26.0177820514447}   \n",
       "\n",
       "                                        \n",
       "                        С стоп-словами  \n",
       "0          {'know': 19.78579921737784}  \n",
       "1          {'like': 17.72640179203392}  \n",
       "2         {'people': 17.7089654853161}  \n",
       "3         {'just': 17.631226432525903}  \n",
       "4          {'don': 17.583760771958584}  \n",
       "5          {'does': 17.22809995409527}  \n",
       "6         {'drive': 16.39874301043245}  \n",
       "7       {'thanks': 15.453835857073658}  \n",
       "8           {'ve': 14.080995472361815}  \n",
       "9           {'use': 14.06988552250666}  \n",
       "10       {'think': 13.975194482131897}  \n",
       "11      {'israel': 13.496273726006486}  \n",
       "12        {'good': 12.577620578291661}  \n",
       "13        {'card': 12.276145758372772}  \n",
       "14         {'did': 11.839884300272598}  \n",
       "15         {'need': 11.59412077354018}  \n",
       "16        {'jews': 11.412098006263552}  \n",
       "17     {'problem': 11.396809292843278}  \n",
       "18     {'muslims': 11.244332076286735}  \n",
       "19  {'information': 10.72185387994127}  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(columns=columns)\n",
    "\n",
    "df2['Count', 'Без стоп-слов'] = top_terms_without_stop_test\n",
    "df2['TF', 'Без стоп-слов'] = top_terms_tf_test\n",
    "df2['TF-IDF', 'Без стоп-слов'] = top_terms_tfidf_test\n",
    "\n",
    "df2['Count', 'С стоп-словами'] = top_terms_stop_test\n",
    "df2['TF', 'С стоп-словами'] = top_terms_stop_tf_test\n",
    "df2['TF-IDF', 'С стоп-словами'] = top_terms_stop_tfidf_test\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8856b13e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Со стеммингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fdd43015",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Count</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TF</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TF-IDF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Без стоп-слов</th>\n",
       "      <th>С стоп-словами</th>\n",
       "      <th>Без стоп-слов</th>\n",
       "      <th>С стоп-словами</th>\n",
       "      <th>Без стоп-слов</th>\n",
       "      <th>С стоп-словами</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'the': 20919}</td>\n",
       "      <td>{'wa': 2470}</td>\n",
       "      <td>{'the': 580.9195455198186}</td>\n",
       "      <td>{'kuvvetli': 54.741560260006736}</td>\n",
       "      <td>{'the': 226.73601702282315}</td>\n",
       "      <td>{'kuvvetli': 54.741560260006736}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'of': 10253}</td>\n",
       "      <td>{'thi': 2422}</td>\n",
       "      <td>{'to': 317.3474366692875}</td>\n",
       "      <td>{'keysystem': 52.77569413890487}</td>\n",
       "      <td>{'to': 128.4318213943837}</td>\n",
       "      <td>{'keysystem': 52.77569413890487}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'to': 9895}</td>\n",
       "      <td>{'armenian': 1123}</td>\n",
       "      <td>{'of': 278.6135135551277}</td>\n",
       "      <td>{'liu': 52.615200558633546}</td>\n",
       "      <td>{'of': 122.29885435480524}</td>\n",
       "      <td>{'liu': 52.615200558633546}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'and': 9305}</td>\n",
       "      <td>{'use': 1113}</td>\n",
       "      <td>{'and': 240.78718078291644}</td>\n",
       "      <td>{'papa': 50.36062593469473}</td>\n",
       "      <td>{'and': 104.03434074458796}</td>\n",
       "      <td>{'papa': 50.36062593469473}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'in': 6686}</td>\n",
       "      <td>{'peopl': 1062}</td>\n",
       "      <td>{'is': 210.61193877763262}</td>\n",
       "      <td>{'drain': 48.3356858391453}</td>\n",
       "      <td>{'is': 91.72437877615828}</td>\n",
       "      <td>{'drain': 48.3356858391453}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'that': 5249}</td>\n",
       "      <td>{'ha': 1033}</td>\n",
       "      <td>{'it': 193.046367308862}</td>\n",
       "      <td>{'download': 43.35324301900809}</td>\n",
       "      <td>{'it': 88.41412066279622}</td>\n",
       "      <td>{'download': 43.35324301900809}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'is': 5082}</td>\n",
       "      <td>{'ani': 923}</td>\n",
       "      <td>{'in': 181.44162075274158}</td>\n",
       "      <td>{'tour': 37.27135075539442}</td>\n",
       "      <td>{'in': 86.40389015137937}</td>\n",
       "      <td>{'tour': 37.27135075539442}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'it': 4834}</td>\n",
       "      <td>{'know': 813}</td>\n",
       "      <td>{'that': 164.96081627832928}</td>\n",
       "      <td>{'tire': 36.292810556154315}</td>\n",
       "      <td>{'that': 79.38729165022512}</td>\n",
       "      <td>{'tire': 36.292810556154315}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'you': 3309}</td>\n",
       "      <td>{'drive': 778}</td>\n",
       "      <td>{'you': 128.50829611456712}</td>\n",
       "      <td>{'joke': 35.5649078550382}</td>\n",
       "      <td>{'you': 74.64096646413044}</td>\n",
       "      <td>{'joke': 35.5649078550382}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'for': 3249}</td>\n",
       "      <td>{'like': 763}</td>\n",
       "      <td>{'for': 113.48764322258968}</td>\n",
       "      <td>{'dunya': 32.30302778343974}</td>\n",
       "      <td>{'for': 57.82953546770416}</td>\n",
       "      <td>{'dunya': 32.30302778343974}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'on': 2653}</td>\n",
       "      <td>{'time': 752}</td>\n",
       "      <td>{'have': 96.35224116826025}</td>\n",
       "      <td>{'eigen': 32.04577092336103}</td>\n",
       "      <td>{'have': 51.02324512463676}</td>\n",
       "      <td>{'eigen': 32.04577092336103}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'with': 2582}</td>\n",
       "      <td>{'hi': 732}</td>\n",
       "      <td>{'thi': 92.78319885420794}</td>\n",
       "      <td>{'va': 31.273268013974864}</td>\n",
       "      <td>{'thi': 50.409120246347435}</td>\n",
       "      <td>{'va': 31.273268013974864}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'not': 2505}</td>\n",
       "      <td>{'did': 702}</td>\n",
       "      <td>{'not': 88.07689480155399}</td>\n",
       "      <td>{'tile': 29.87072552182338}</td>\n",
       "      <td>{'not': 49.86390651191747}</td>\n",
       "      <td>{'tile': 29.87072552182338}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'are': 2473}</td>\n",
       "      <td>{'onli': 684}</td>\n",
       "      <td>{'be': 86.95367114840924}</td>\n",
       "      <td>{'hada': 26.74248581100969}</td>\n",
       "      <td>{'are': 49.66775892441848}</td>\n",
       "      <td>{'hada': 26.74248581100969}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'wa': 2470}</td>\n",
       "      <td>{'just': 678}</td>\n",
       "      <td>{'with': 86.61804035263049}</td>\n",
       "      <td>{'broccoli': 26.492309800567398}</td>\n",
       "      <td>{'be': 48.57961627372931}</td>\n",
       "      <td>{'broccoli': 26.492309800567398}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'they': 2458}</td>\n",
       "      <td>{'say': 666}</td>\n",
       "      <td>{'on': 85.5882724969143}</td>\n",
       "      <td>{'powel': 26.022392993607035}</td>\n",
       "      <td>{'on': 47.70476608122967}</td>\n",
       "      <td>{'powel': 26.022392993607035}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'have': 2439}</td>\n",
       "      <td>{'said': 617}</td>\n",
       "      <td>{'are': 84.31941150127194}</td>\n",
       "      <td>{'honeywell': 25.264808465903076}</td>\n",
       "      <td>{'with': 47.00092217462357}</td>\n",
       "      <td>{'honeywell': 25.264808465903076}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'thi': 2422}</td>\n",
       "      <td>{'edu': 587}</td>\n",
       "      <td>{'do': 73.39506975724343}</td>\n",
       "      <td>{'dip': 24.7113547918968}</td>\n",
       "      <td>{'do': 44.72365073513757}</td>\n",
       "      <td>{'dip': 24.7113547918968}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'be': 2385}</td>\n",
       "      <td>{'doe': 583}</td>\n",
       "      <td>{'as': 65.75951900628384}</td>\n",
       "      <td>{'ndw': 24.524137168129766}</td>\n",
       "      <td>{'as': 42.21231611823069}</td>\n",
       "      <td>{'ndw': 24.524137168129766}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'as': 2060}</td>\n",
       "      <td>{'becaus': 568}</td>\n",
       "      <td>{'or': 64.80237842415754}</td>\n",
       "      <td>{'weyrich': 23.039159762462827}</td>\n",
       "      <td>{'my': 39.14384832245557}</td>\n",
       "      <td>{'weyrich': 23.039159762462827}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Count                                                TF  \\\n",
       "     Без стоп-слов      С стоп-словами                 Без стоп-слов   \n",
       "0   {'the': 20919}        {'wa': 2470}    {'the': 580.9195455198186}   \n",
       "1    {'of': 10253}       {'thi': 2422}     {'to': 317.3474366692875}   \n",
       "2     {'to': 9895}  {'armenian': 1123}     {'of': 278.6135135551277}   \n",
       "3    {'and': 9305}       {'use': 1113}   {'and': 240.78718078291644}   \n",
       "4     {'in': 6686}     {'peopl': 1062}    {'is': 210.61193877763262}   \n",
       "5   {'that': 5249}        {'ha': 1033}      {'it': 193.046367308862}   \n",
       "6     {'is': 5082}        {'ani': 923}    {'in': 181.44162075274158}   \n",
       "7     {'it': 4834}       {'know': 813}  {'that': 164.96081627832928}   \n",
       "8    {'you': 3309}      {'drive': 778}   {'you': 128.50829611456712}   \n",
       "9    {'for': 3249}       {'like': 763}   {'for': 113.48764322258968}   \n",
       "10    {'on': 2653}       {'time': 752}   {'have': 96.35224116826025}   \n",
       "11  {'with': 2582}         {'hi': 732}    {'thi': 92.78319885420794}   \n",
       "12   {'not': 2505}        {'did': 702}    {'not': 88.07689480155399}   \n",
       "13   {'are': 2473}       {'onli': 684}     {'be': 86.95367114840924}   \n",
       "14    {'wa': 2470}       {'just': 678}   {'with': 86.61804035263049}   \n",
       "15  {'they': 2458}        {'say': 666}      {'on': 85.5882724969143}   \n",
       "16  {'have': 2439}       {'said': 617}    {'are': 84.31941150127194}   \n",
       "17   {'thi': 2422}        {'edu': 587}     {'do': 73.39506975724343}   \n",
       "18    {'be': 2385}        {'doe': 583}     {'as': 65.75951900628384}   \n",
       "19    {'as': 2060}     {'becaus': 568}     {'or': 64.80237842415754}   \n",
       "\n",
       "                                                            TF-IDF  \\\n",
       "                       С стоп-словами                Без стоп-слов   \n",
       "0    {'kuvvetli': 54.741560260006736}  {'the': 226.73601702282315}   \n",
       "1    {'keysystem': 52.77569413890487}    {'to': 128.4318213943837}   \n",
       "2         {'liu': 52.615200558633546}   {'of': 122.29885435480524}   \n",
       "3         {'papa': 50.36062593469473}  {'and': 104.03434074458796}   \n",
       "4         {'drain': 48.3356858391453}    {'is': 91.72437877615828}   \n",
       "5     {'download': 43.35324301900809}    {'it': 88.41412066279622}   \n",
       "6         {'tour': 37.27135075539442}    {'in': 86.40389015137937}   \n",
       "7        {'tire': 36.292810556154315}  {'that': 79.38729165022512}   \n",
       "8          {'joke': 35.5649078550382}   {'you': 74.64096646413044}   \n",
       "9        {'dunya': 32.30302778343974}   {'for': 57.82953546770416}   \n",
       "10       {'eigen': 32.04577092336103}  {'have': 51.02324512463676}   \n",
       "11         {'va': 31.273268013974864}  {'thi': 50.409120246347435}   \n",
       "12        {'tile': 29.87072552182338}   {'not': 49.86390651191747}   \n",
       "13        {'hada': 26.74248581100969}   {'are': 49.66775892441848}   \n",
       "14   {'broccoli': 26.492309800567398}    {'be': 48.57961627372931}   \n",
       "15      {'powel': 26.022392993607035}    {'on': 47.70476608122967}   \n",
       "16  {'honeywell': 25.264808465903076}  {'with': 47.00092217462357}   \n",
       "17          {'dip': 24.7113547918968}    {'do': 44.72365073513757}   \n",
       "18        {'ndw': 24.524137168129766}    {'as': 42.21231611823069}   \n",
       "19    {'weyrich': 23.039159762462827}    {'my': 39.14384832245557}   \n",
       "\n",
       "                                       \n",
       "                       С стоп-словами  \n",
       "0    {'kuvvetli': 54.741560260006736}  \n",
       "1    {'keysystem': 52.77569413890487}  \n",
       "2         {'liu': 52.615200558633546}  \n",
       "3         {'papa': 50.36062593469473}  \n",
       "4         {'drain': 48.3356858391453}  \n",
       "5     {'download': 43.35324301900809}  \n",
       "6         {'tour': 37.27135075539442}  \n",
       "7        {'tire': 36.292810556154315}  \n",
       "8          {'joke': 35.5649078550382}  \n",
       "9        {'dunya': 32.30302778343974}  \n",
       "10       {'eigen': 32.04577092336103}  \n",
       "11         {'va': 31.273268013974864}  \n",
       "12        {'tile': 29.87072552182338}  \n",
       "13        {'hada': 26.74248581100969}  \n",
       "14   {'broccoli': 26.492309800567398}  \n",
       "15      {'powel': 26.022392993607035}  \n",
       "16  {'honeywell': 25.264808465903076}  \n",
       "17          {'dip': 24.7113547918968}  \n",
       "18        {'ndw': 24.524137168129766}  \n",
       "19    {'weyrich': 23.039159762462827}  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame(columns=columns)\n",
    "\n",
    "df3['Count', 'Без стоп-слов'] = top_terms_stem\n",
    "df3['TF', 'Без стоп-слов'] = top_terms_stem_tf\n",
    "df3['TF-IDF', 'Без стоп-слов'] = top_terms_stem_tfidf\n",
    "\n",
    "df3['Count', 'С стоп-словами'] = top_terms_stop_stem\n",
    "df3['TF', 'С стоп-словами'] = top_terms_stem_stop_tf\n",
    "df3['TF-IDF', 'С стоп-словами'] = top_terms_stem_stop_tfidf\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90d00b31",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Count</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TF</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TF-IDF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Без стоп-слов</th>\n",
       "      <th>С стоп-словами</th>\n",
       "      <th>Без стоп-слов</th>\n",
       "      <th>С стоп-словами</th>\n",
       "      <th>Без стоп-слов</th>\n",
       "      <th>С стоп-словами</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'the': 14650}</td>\n",
       "      <td>{'thi': 1654}</td>\n",
       "      <td>{'the': 393.8825021805069}</td>\n",
       "      <td>{'kuvvetli': 38.58159096500337}</td>\n",
       "      <td>{'the': 157.2388941502928}</td>\n",
       "      <td>{'kuvvetli': 38.58159096500337}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'of': 7249}</td>\n",
       "      <td>{'wa': 1508}</td>\n",
       "      <td>{'to': 212.70394281586968}</td>\n",
       "      <td>{'liu': 36.12468490625079}</td>\n",
       "      <td>{'to': 88.25882757708708}</td>\n",
       "      <td>{'liu': 36.12468490625079}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'to': 6580}</td>\n",
       "      <td>{'ha': 748}</td>\n",
       "      <td>{'of': 183.61602638204053}</td>\n",
       "      <td>{'keysystem': 35.07900385428372}</td>\n",
       "      <td>{'of': 82.15071361679951}</td>\n",
       "      <td>{'keysystem': 35.07900385428372}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'and': 6307}</td>\n",
       "      <td>{'armenian': 706}</td>\n",
       "      <td>{'and': 165.45839194498524}</td>\n",
       "      <td>{'papa': 33.899805109818885}</td>\n",
       "      <td>{'and': 72.81946837666995}</td>\n",
       "      <td>{'papa': 33.899805109818885}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'in': 4664}</td>\n",
       "      <td>{'use': 687}</td>\n",
       "      <td>{'is': 133.29227227576882}</td>\n",
       "      <td>{'drain': 33.22247165159427}</td>\n",
       "      <td>{'in': 59.67514134362165}</td>\n",
       "      <td>{'drain': 33.22247165159427}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'is': 3244}</td>\n",
       "      <td>{'peopl': 577}</td>\n",
       "      <td>{'in': 122.3052103845949}</td>\n",
       "      <td>{'download': 31.356326600450455}</td>\n",
       "      <td>{'is': 58.74700675437686}</td>\n",
       "      <td>{'download': 31.356326600450455}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'that': 3201}</td>\n",
       "      <td>{'ani': 551}</td>\n",
       "      <td>{'it': 109.05515745423625}</td>\n",
       "      <td>{'tire': 24.756486685752243}</td>\n",
       "      <td>{'that': 53.114529463275495}</td>\n",
       "      <td>{'tire': 24.756486685752243}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'it': 2798}</td>\n",
       "      <td>{'like': 476}</td>\n",
       "      <td>{'that': 107.48290520963673}</td>\n",
       "      <td>{'va': 23.68612643837865}</td>\n",
       "      <td>{'it': 50.782768659461645}</td>\n",
       "      <td>{'va': 23.68612643837865}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'for': 2343}</td>\n",
       "      <td>{'know': 452}</td>\n",
       "      <td>{'for': 81.34252982190382}</td>\n",
       "      <td>{'tile': 23.60052634582734}</td>\n",
       "      <td>{'you': 45.24027565870208}</td>\n",
       "      <td>{'tile': 23.60052634582734}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'on': 1809}</td>\n",
       "      <td>{'hi': 418}</td>\n",
       "      <td>{'you': 75.6859615361589}</td>\n",
       "      <td>{'dunya': 21.770502304466586}</td>\n",
       "      <td>{'for': 42.32351737189909}</td>\n",
       "      <td>{'dunya': 21.770502304466586}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'you': 1798}</td>\n",
       "      <td>{'time': 408}</td>\n",
       "      <td>{'have': 69.20996614485878}</td>\n",
       "      <td>{'vertic': 21.18233857137946}</td>\n",
       "      <td>{'have': 37.89706132683007}</td>\n",
       "      <td>{'vertic': 21.18233857137946}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'with': 1691}</td>\n",
       "      <td>{'just': 407}</td>\n",
       "      <td>{'thi': 67.92376484399286}</td>\n",
       "      <td>{'hada': 19.81800160459357}</td>\n",
       "      <td>{'thi': 37.640352013093114}</td>\n",
       "      <td>{'hada': 19.81800160459357}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'have': 1668}</td>\n",
       "      <td>{'doe': 390}</td>\n",
       "      <td>{'on': 57.93501770971535}</td>\n",
       "      <td>{'tour': 19.631632693113296}</td>\n",
       "      <td>{'on': 32.969598013545124}</td>\n",
       "      <td>{'tour': 19.631632693113296}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'thi': 1654}</td>\n",
       "      <td>{'muslim': 376}</td>\n",
       "      <td>{'not': 55.61804308266621}</td>\n",
       "      <td>{'joke': 19.001475698647734}</td>\n",
       "      <td>{'are': 32.733953715289694}</td>\n",
       "      <td>{'joke': 19.001475698647734}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'be': 1532}</td>\n",
       "      <td>{'onli': 371}</td>\n",
       "      <td>{'with': 54.98452705060883}</td>\n",
       "      <td>{'dip': 18.620097671734133}</td>\n",
       "      <td>{'not': 32.53959169338456}</td>\n",
       "      <td>{'dip': 18.620097671734133}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'not': 1532}</td>\n",
       "      <td>{'did': 369}</td>\n",
       "      <td>{'are': 54.48411532873619}</td>\n",
       "      <td>{'powel': 18.270319216644406}</td>\n",
       "      <td>{'do': 32.37287087935601}</td>\n",
       "      <td>{'powel': 18.270319216644406}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'as': 1531}</td>\n",
       "      <td>{'said': 366}</td>\n",
       "      <td>{'be': 54.28869092725317}</td>\n",
       "      <td>{'nan': 17.341536187667092}</td>\n",
       "      <td>{'be': 31.33777132043142}</td>\n",
       "      <td>{'nan': 17.341536187667092}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'are': 1511}</td>\n",
       "      <td>{'year': 360}</td>\n",
       "      <td>{'do': 51.98500680932219}</td>\n",
       "      <td>{'broccoli': 16.80690032882596}</td>\n",
       "      <td>{'with': 30.746733916646296}</td>\n",
       "      <td>{'broccoli': 16.80690032882596}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'wa': 1508}</td>\n",
       "      <td>{'work': 342}</td>\n",
       "      <td>{'as': 44.83158523890473}</td>\n",
       "      <td>{'honeywell': 16.734896985500633}</td>\n",
       "      <td>{'as': 29.68626987221284}</td>\n",
       "      <td>{'honeywell': 16.734896985500633}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'by': 1338}</td>\n",
       "      <td>{'new': 330}</td>\n",
       "      <td>{'or': 44.795997941256026}</td>\n",
       "      <td>{'weyrich': 16.175907790854883}</td>\n",
       "      <td>{'or': 27.490714607187865}</td>\n",
       "      <td>{'weyrich': 16.175907790854883}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Count                                               TF  \\\n",
       "     Без стоп-слов     С стоп-словами                 Без стоп-слов   \n",
       "0   {'the': 14650}      {'thi': 1654}    {'the': 393.8825021805069}   \n",
       "1     {'of': 7249}       {'wa': 1508}    {'to': 212.70394281586968}   \n",
       "2     {'to': 6580}        {'ha': 748}    {'of': 183.61602638204053}   \n",
       "3    {'and': 6307}  {'armenian': 706}   {'and': 165.45839194498524}   \n",
       "4     {'in': 4664}       {'use': 687}    {'is': 133.29227227576882}   \n",
       "5     {'is': 3244}     {'peopl': 577}     {'in': 122.3052103845949}   \n",
       "6   {'that': 3201}       {'ani': 551}    {'it': 109.05515745423625}   \n",
       "7     {'it': 2798}      {'like': 476}  {'that': 107.48290520963673}   \n",
       "8    {'for': 2343}      {'know': 452}    {'for': 81.34252982190382}   \n",
       "9     {'on': 1809}        {'hi': 418}     {'you': 75.6859615361589}   \n",
       "10   {'you': 1798}      {'time': 408}   {'have': 69.20996614485878}   \n",
       "11  {'with': 1691}      {'just': 407}    {'thi': 67.92376484399286}   \n",
       "12  {'have': 1668}       {'doe': 390}     {'on': 57.93501770971535}   \n",
       "13   {'thi': 1654}    {'muslim': 376}    {'not': 55.61804308266621}   \n",
       "14    {'be': 1532}      {'onli': 371}   {'with': 54.98452705060883}   \n",
       "15   {'not': 1532}       {'did': 369}    {'are': 54.48411532873619}   \n",
       "16    {'as': 1531}      {'said': 366}     {'be': 54.28869092725317}   \n",
       "17   {'are': 1511}      {'year': 360}     {'do': 51.98500680932219}   \n",
       "18    {'wa': 1508}      {'work': 342}     {'as': 44.83158523890473}   \n",
       "19    {'by': 1338}       {'new': 330}    {'or': 44.795997941256026}   \n",
       "\n",
       "                                                             TF-IDF  \\\n",
       "                       С стоп-словами                 Без стоп-слов   \n",
       "0     {'kuvvetli': 38.58159096500337}    {'the': 157.2388941502928}   \n",
       "1          {'liu': 36.12468490625079}     {'to': 88.25882757708708}   \n",
       "2    {'keysystem': 35.07900385428372}     {'of': 82.15071361679951}   \n",
       "3        {'papa': 33.899805109818885}    {'and': 72.81946837666995}   \n",
       "4        {'drain': 33.22247165159427}     {'in': 59.67514134362165}   \n",
       "5    {'download': 31.356326600450455}     {'is': 58.74700675437686}   \n",
       "6        {'tire': 24.756486685752243}  {'that': 53.114529463275495}   \n",
       "7           {'va': 23.68612643837865}    {'it': 50.782768659461645}   \n",
       "8         {'tile': 23.60052634582734}    {'you': 45.24027565870208}   \n",
       "9       {'dunya': 21.770502304466586}    {'for': 42.32351737189909}   \n",
       "10      {'vertic': 21.18233857137946}   {'have': 37.89706132683007}   \n",
       "11        {'hada': 19.81800160459357}   {'thi': 37.640352013093114}   \n",
       "12       {'tour': 19.631632693113296}    {'on': 32.969598013545124}   \n",
       "13       {'joke': 19.001475698647734}   {'are': 32.733953715289694}   \n",
       "14        {'dip': 18.620097671734133}    {'not': 32.53959169338456}   \n",
       "15      {'powel': 18.270319216644406}     {'do': 32.37287087935601}   \n",
       "16        {'nan': 17.341536187667092}     {'be': 31.33777132043142}   \n",
       "17    {'broccoli': 16.80690032882596}  {'with': 30.746733916646296}   \n",
       "18  {'honeywell': 16.734896985500633}     {'as': 29.68626987221284}   \n",
       "19    {'weyrich': 16.175907790854883}    {'or': 27.490714607187865}   \n",
       "\n",
       "                                       \n",
       "                       С стоп-словами  \n",
       "0     {'kuvvetli': 38.58159096500337}  \n",
       "1          {'liu': 36.12468490625079}  \n",
       "2    {'keysystem': 35.07900385428372}  \n",
       "3        {'papa': 33.899805109818885}  \n",
       "4        {'drain': 33.22247165159427}  \n",
       "5    {'download': 31.356326600450455}  \n",
       "6        {'tire': 24.756486685752243}  \n",
       "7           {'va': 23.68612643837865}  \n",
       "8         {'tile': 23.60052634582734}  \n",
       "9       {'dunya': 21.770502304466586}  \n",
       "10      {'vertic': 21.18233857137946}  \n",
       "11        {'hada': 19.81800160459357}  \n",
       "12       {'tour': 19.631632693113296}  \n",
       "13       {'joke': 19.001475698647734}  \n",
       "14        {'dip': 18.620097671734133}  \n",
       "15      {'powel': 18.270319216644406}  \n",
       "16        {'nan': 17.341536187667092}  \n",
       "17    {'broccoli': 16.80690032882596}  \n",
       "18  {'honeywell': 16.734896985500633}  \n",
       "19    {'weyrich': 16.175907790854883}  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.DataFrame(columns=columns)\n",
    "\n",
    "df4['Count', 'Без стоп-слов'] = top_terms_stem_test\n",
    "df4['TF', 'Без стоп-слов'] = top_terms_stem_tf_test\n",
    "df4['TF-IDF', 'Без стоп-слов'] = top_terms_stem_tfidf_test\n",
    "\n",
    "df4['Count', 'С стоп-словами'] = top_terms_stop_stem_test\n",
    "df4['TF', 'С стоп-словами'] = top_terms_stem_stop_tf_test\n",
    "df4['TF-IDF', 'С стоп-словами'] = top_terms_stem_stop_tfidf_test\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1398b563",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Запись в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed81e668",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ceff0f2a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('result.xlsx', engine='openpyxl')\n",
    "\n",
    "df1.to_excel(writer, sheet_name='Train, wo stem')\n",
    "df2.to_excel(writer, sheet_name='Test, wo stem')\n",
    "df3.to_excel(writer, sheet_name='Train, with stem')\n",
    "df4.to_excel(writer, sheet_name='Test, with stem')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cf3bf1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Используя конвейер (Pipeline) реализовать модель Наивного\n",
    "Байесовского классификатора и выявить на основе показателей\n",
    "качества ### Конвейер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6843061",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aede3418",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = [None, 'english']\n",
    "max_features_values = [100, 500, 1000, 2000, 3000, 4000, 5000]\n",
    "use_tf = [True, False]\n",
    "use_idf = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61f995ac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prepare(data, max_feature, stop_word, use_tf, use_idf):\n",
    "    tf = None\n",
    "    cv = CountVectorizer(max_features=max_feature, stop_words=stop_word)\n",
    "    cv.fit(data)\n",
    "    if use_tf:\n",
    "        tf = TfidfTransformer(use_idf=use_idf)\n",
    "        tf.fit(cv.transform(data))\n",
    "    return cv, tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10d5c93e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for max_features_value in max_features_values:\n",
    "    for stop_word in stop_words:\n",
    "        for ut in use_tf:\n",
    "            for ui in use_idf:\n",
    "                options = {}\n",
    "                cv, tf = prepare(twenty_train_full.data, max_features_value, stop_word, ut, ui)\n",
    "                if tf:\n",
    "                    clf = MultinomialNB()\n",
    "                    clf.fit(tf.transform(cv.transform(twenty_train_full.data)), twenty_train_full.target)\n",
    "                    prep_test = tf.transform(cv.transform(twenty_test_full.data))\n",
    "                else:\n",
    "                    clf = MultinomialNB()\n",
    "                    clf.fit(cv.transform(twenty_train_full.data), twenty_train_full.target)\n",
    "                    prep_test = cv.transform(twenty_test_full.data)\n",
    "\n",
    "                options['features'] = max_features_value\n",
    "                options['stop_words'] = stop_word\n",
    "                options['use_tf'] = ut\n",
    "                options['use_idf'] = ui\n",
    "\n",
    "                result_data = classification_report(clf.predict(prep_test), twenty_test_full.target, output_dict=True)\n",
    "                result_df = pd.DataFrame(result_data)\n",
    "                result.append({\n",
    "                    'df': result_df,\n",
    "                    'options': options\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "014351f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('result_compare.xlsx', engine='openpyxl')\n",
    "\n",
    "df = pd.DataFrame(columns=['Номер страницы', 'features', 'stop_words', 'use_tf', 'use_idf'])\n",
    "for it, item in enumerate(result):\n",
    "    for key, value in item['options'].items():\n",
    "        df.at[it, key] = value\n",
    "    df.at[it, 'Номер страницы'] = it\n",
    "\n",
    "df.to_excel(writer, sheet_name='Оглавление')\n",
    "\n",
    "for it, item in enumerate(result):\n",
    "    df_new = pd.DataFrame(item['df'])\n",
    "    df_new.to_excel(writer, sheet_name=f'Страница {it}')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75ca7bd1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_features': max_features_values,\n",
    "    'vect__stop_words': stop_words,\n",
    "    'tfidf__use_idf': use_idf\n",
    "}\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f1c3b4c4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                                       (&#x27;clf&#x27;, MultinomialNB())]),\n",
       "             param_grid={&#x27;tfidf__use_idf&#x27;: [True, False],\n",
       "                         &#x27;vect__max_features&#x27;: [100, 500, 1000, 2000, 3000,\n",
       "                                                4000, 5000],\n",
       "                         &#x27;vect__stop_words&#x27;: [None, &#x27;english&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                                       (&#x27;clf&#x27;, MultinomialNB())]),\n",
       "             param_grid={&#x27;tfidf__use_idf&#x27;: [True, False],\n",
       "                         &#x27;vect__max_features&#x27;: [100, 500, 1000, 2000, 3000,\n",
       "                                                4000, 5000],\n",
       "                         &#x27;vect__stop_words&#x27;: [None, &#x27;english&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf', MultinomialNB())]),\n",
       "             param_grid={'tfidf__use_idf': [True, False],\n",
       "                         'vect__max_features': [100, 500, 1000, 2000, 3000,\n",
       "                                                4000, 5000],\n",
       "                         'vect__stop_words': [None, 'english']})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gscv = GridSearchCV(text_clf, param_grid=parameters)\n",
    "gscv.fit(twenty_train_full.data, twenty_train_full.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "474a2d1b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96       404\n",
      "           1       0.92      0.92      0.92       393\n",
      "           2       0.93      0.95      0.94       367\n",
      "\n",
      "    accuracy                           0.94      1164\n",
      "   macro avg       0.94      0.94      0.94      1164\n",
      "weighted avg       0.94      0.94      0.94      1164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(gscv.predict(twenty_test_full.data), twenty_test_full.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "66b7df28",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__use_idf': True,\n",
       " 'vect__max_features': 5000,\n",
       " 'vect__stop_words': 'english'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
